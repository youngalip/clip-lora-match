model:
  base_model_name: "openai/clip-vit-base-patch32"
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "out_proj"

lora:
  r: 8
  alpha: 16
  dropout: 0.1
  bias: "none"
  task_type: "FEATURE_EXTRACTION"

data:
  train_csv: "data/text/train_fashion.csv"
  val_csv: "data/text/val_fashion.csv"
  image_root_dir: "."

training:
  seed: 42
  batch_size: 8
  num_workers: 2
  learning_rate: 1e-4
  weight_decay: 0.01
  num_epochs: 1
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  logging_steps: 50
  temperature: 0.07
  warmup_ratio: 0.1
  output_dir: "models/saved/clip-lora"
